{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dữ liệu được lấy từ: https://github.com/ds4v/vietnamese-pos-tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import unicodedata as ud\n",
    "import numpy as np\n",
    "import math\n",
    "import ast\n",
    "import re"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thu thập dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = open('dataset/sentences.txt', encoding='utf-8').readlines()\n",
    "tokenize_sentences = [sentence.split(' ') for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng câu đã thu thập: 60\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Pha lập công trên đã giúp Rashford giải hạn bàn thắng tại sân Old Trafford kéo dài 845 phút .\\n',\n",
       " 'Với 3 điểm có được trong trận đấu này , Quỷ đỏ đã leo lên vị trí thứ 2 trên bảng xếp hạng Premier League với 30 điểm , chỉ kém đội đầu bảng Liverpool 2 điểm .\\n']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Số lượng câu đã thu thập:', len(sentences))\n",
    "sentences[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Câu có số từ nhiều nhât: 46\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Những thực phẩm được chế biến như hun khói , thức ăn ngâm tẩm , muối , món ăn chứa lượng muối cao thường có tỷ lệ mắc ung thư dạ dày cao hơn những người có thói quen ăn uống nhạt và thanh đạm .\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_str = max(tokenize_sentences, key=len)\n",
    "print('Câu có số từ nhiều nhât:', len(max_str))\n",
    "' '.join(max_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Câu có số từ ít nhât: 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Nhiều người có hoàn cảnh giống ông .\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_str = min(tokenize_sentences, key=len)\n",
    "print('Câu có số từ ít nhât:', len(min_str))\n",
    "' '.join(min_str)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tách từ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def syllablize(sentence): # Tách âm tiết cho một câu tiếng Việt\n",
    "    word = '\\w+'\n",
    "    non_word = '[^\\w\\s]'\n",
    "    digits = '\\d+([\\.,_]\\d+)+'\n",
    "    \n",
    "    patterns = []\n",
    "    patterns.extend([word, non_word, digits])\n",
    "    patterns = f\"({'|'.join(patterns)})\"\n",
    "    \n",
    "    sentence = ud.normalize('NFC', sentence)\n",
    "    tokens = re.findall(patterns, sentence, re.UNICODE)\n",
    "    return [token[0] for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Với',\n",
       " '3',\n",
       " 'điểm',\n",
       " 'có',\n",
       " 'được',\n",
       " 'trong',\n",
       " 'trận',\n",
       " 'đấu',\n",
       " 'này',\n",
       " ',',\n",
       " 'Quỷ',\n",
       " 'đỏ',\n",
       " 'đã',\n",
       " 'leo',\n",
       " 'lên',\n",
       " 'vị',\n",
       " 'trí',\n",
       " 'thứ',\n",
       " '2',\n",
       " 'trên',\n",
       " 'bảng',\n",
       " 'xếp',\n",
       " 'hạng',\n",
       " 'Premier',\n",
       " 'League',\n",
       " 'với',\n",
       " '30',\n",
       " 'điểm',\n",
       " ',',\n",
       " 'chỉ',\n",
       " 'kém',\n",
       " 'đội',\n",
       " 'đầu',\n",
       " 'bảng',\n",
       " 'Liverpool',\n",
       " '2',\n",
       " 'điểm',\n",
       " '.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syllables = syllablize(sentences[1])\n",
    "syllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng từ ghép và cụm từ trong vocab: 112343\n",
      "Số bộ vocab phân theo độ dài: 20\n"
     ]
    }
   ],
   "source": [
    "# Tải từ trong vi-vocab.txt\n",
    "with open('data/dic3.txt', encoding='utf8') as f:\n",
    "    vocab = f.read().split('\\n')\n",
    "# Xây dựng từ điển vocabs theo độ dài từ\n",
    "vocabs = defaultdict(list)\n",
    "for word in vocab:\n",
    "    vocabs[len(word.split())].append(word)\n",
    "\n",
    "print('Số lượng từ ghép và cụm từ trong vocab:', len(vocab))\n",
    "print('Số bộ vocab phân theo độ dài:', len(vocabs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def longest_matching(sentence, vocabs):\n",
    "  words = syllablize(sentence) # tách âm tiết cho câu\n",
    "  result = []\n",
    "  i = len(words)-1 # index của từ hiện tại\n",
    "  while i > -1: \n",
    "    word = '' \n",
    "    # tìm kiếm trong từ điển theo chiều dài của từ ưu tiên từ dài trước\n",
    "    for j in range(i+1):\n",
    "      ls_word = words[j:i+1]\n",
    "      word = ' '.join(ls_word)\n",
    "      # xem thử có trong từ điển không\n",
    "      if word.lower() in vocabs[len(ls_word)]:\n",
    "        i = j\n",
    "        break\n",
    "    result = [word] + result\n",
    "    i-=1\n",
    "  return result # return the final list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Câu: Pha lập công trên đã giúp Rashford giải hạn bàn thắng tại sân Old Trafford kéo dài 845 phút .\n",
      "\n",
      "Tách từ: ['Pha', 'lập', 'công', 'trên', 'đã', 'giúp', 'Rashford', 'giải', 'hạn', 'bàn', 'thắng', 'tại', 'sân', 'Old', 'Trafford', 'kéo', 'dài', '845', 'phút', '.']\n",
      "Tách từ dài nhất: ['Pha', 'lập công', 'trên', 'đã', 'giúp', 'Rashford', 'giải hạn', 'bàn thắng', 'tại', 'sân', 'Old', 'Trafford', 'kéo dài', '845', 'phút', '.']\n",
      "---------------------------------------------------\n",
      "Câu: Với 3 điểm có được trong trận đấu này , Quỷ đỏ đã leo lên vị trí thứ 2 trên bảng xếp hạng Premier League với 30 điểm , chỉ kém đội đầu bảng Liverpool 2 điểm .\n",
      "\n",
      "Tách từ: ['Với', '3', 'điểm', 'có', 'được', 'trong', 'trận', 'đấu', 'này', ',', 'Quỷ', 'đỏ', 'đã', 'leo', 'lên', 'vị', 'trí', 'thứ', '2', 'trên', 'bảng', 'xếp', 'hạng', 'Premier', 'League', 'với', '30', 'điểm', ',', 'chỉ', 'kém', 'đội', 'đầu', 'bảng', 'Liverpool', '2', 'điểm', '.']\n",
      "Tách từ dài nhất: ['Với', '3', 'điểm', 'có được', 'trong', 'trận đấu', 'này', ',', 'Quỷ', 'đỏ', 'đã', 'leo lên', 'vị trí', 'thứ 2', 'trên', 'bảng xếp hạng', 'Premier', 'League', 'với', '30', 'điểm', ',', 'chỉ', 'kém', 'đội', 'đầu bảng', 'Liverpool', '2', 'điểm', '.']\n",
      "---------------------------------------------------\n",
      "Câu: Tổng thống đắc cử Joe Biden được cho đang cân nhắc việc cắt bỏ chương trình hiện đại hóa hạt nhân trị giá 1.000 tỷ USD do chính quyền Tổng thống đương nhiệm Donald Trump đề xuất .\n",
      "\n",
      "Tách từ: ['Tổng', 'thống', 'đắc', 'cử', 'Joe', 'Biden', 'được', 'cho', 'đang', 'cân', 'nhắc', 'việc', 'cắt', 'bỏ', 'chương', 'trình', 'hiện', 'đại', 'hóa', 'hạt', 'nhân', 'trị', 'giá', '1', '.', '000', 'tỷ', 'USD', 'do', 'chính', 'quyền', 'Tổng', 'thống', 'đương', 'nhiệm', 'Donald', 'Trump', 'đề', 'xuất', '.']\n",
      "Tách từ dài nhất: ['Tổng thống', 'đắc cử', 'Joe', 'Biden', 'được', 'cho đang', 'cân nhắc', 'việc cắt bỏ', 'chương trình', 'hiện đại', 'hóa', 'hạt nhân', 'trị giá', '1', '.', '000', 'tỷ', 'USD', 'do', 'chính quyền', 'Tổng thống', 'đương nhiệm', 'Donald', 'Trump', 'đề xuất', '.']\n",
      "---------------------------------------------------\n",
      "Câu: Theo các nguồn tin , trong nhiệm kỳ 1 , chính quyền Trump dường như đã nỗ lực trong việc tăng cường kho vũ khí hạt nhân của Mỹ thông qua phát triển thêm khí tài mới .\n",
      "\n",
      "Tách từ: ['Theo', 'các', 'nguồn', 'tin', ',', 'trong', 'nhiệm', 'kỳ', '1', ',', 'chính', 'quyền', 'Trump', 'dường', 'như', 'đã', 'nỗ', 'lực', 'trong', 'việc', 'tăng', 'cường', 'kho', 'vũ', 'khí', 'hạt', 'nhân', 'của', 'Mỹ', 'thông', 'qua', 'phát', 'triển', 'thêm', 'khí', 'tài', 'mới', '.']\n",
      "Tách từ dài nhất: ['Theo', 'các', 'nguồn tin', ',', 'trong', 'nhiệm kỳ', '1', ',', 'chính quyền', 'Trump', 'dường như', 'đã', 'nỗ lực', 'trong', 'việc', 'tăng cường', 'kho', 'vũ khí hạt nhân', 'của', 'Mỹ', 'thông qua', 'phát triển', 'thêm', 'khí tài', 'mới', '.']\n",
      "---------------------------------------------------\n",
      "Câu: Việc tiến hành sàng lọc và điều trị dự phòng mang lại hiệu quả tích cực bởi ung thư dạ dày nếu phát hiện ở giai đoạn sớm thì vẫn có khả năng điều trị thành công .\n",
      "\n",
      "Tách từ: ['Việc', 'tiến', 'hành', 'sàng', 'lọc', 'và', 'điều', 'trị', 'dự', 'phòng', 'mang', 'lại', 'hiệu', 'quả', 'tích', 'cực', 'bởi', 'ung', 'thư', 'dạ', 'dày', 'nếu', 'phát', 'hiện', 'ở', 'giai', 'đoạn', 'sớm', 'thì', 'vẫn', 'có', 'khả', 'năng', 'điều', 'trị', 'thành', 'công', '.']\n",
      "Tách từ dài nhất: ['Việc', 'tiến hành', 'sàng lọc', 'và', 'điều trị', 'dự phòng', 'mang lại', 'hiệu quả', 'tích cực', 'bởi', 'ung thư', 'dạ dày', 'nếu', 'phát hiện', 'ở', 'giai đoạn', 'sớm', 'thì', 'vẫn', 'có khả năng', 'điều trị', 'thành công', '.']\n",
      "---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences[0:5]:\n",
    "  print('Câu:', sentence)\n",
    "  print('Tách từ:', syllablize(sentence))\n",
    "  print('Tách từ dài nhất:', longest_matching(sentence, vocabs))\n",
    "  print('---------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nhưng', 'sự thực hiện', 'vẫn còn', 'chưa', 'phù hợp']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longest_matching('nhưng sự thực hiện vẫn còn chưa phù hợp', vocabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pha lập_công trên đã giúp Rashford giải_hạn bàn_thắng tại sân Old Trafford kéo_dài 845 phút .'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_sentences(sentence):\n",
    "    return ' '.join([x.replace(' ','_') for x in longest_matching(sentence, vocabs)])\n",
    "\n",
    "tokenize_sentences(sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pha lập_công trên đã giúp Rashford giải_hạn bàn_thắng tại sân Old Trafford kéo_dài 845 phút .',\n",
       " 'Với 3 điểm có_được trong trận_đấu này , Quỷ đỏ đã leo_lên vị_trí thứ_2 trên bảng_xếp_hạng Premier League với 30 điểm , chỉ kém đội đầu_bảng Liverpool 2 điểm .',\n",
       " 'Tổng_thống đắc_cử Joe Biden được cho_đang cân_nhắc việc_cắt_bỏ chương_trình hiện_đại hóa hạt_nhân trị_giá 1 . 000 tỷ USD do chính_quyền Tổng_thống đương_nhiệm Donald Trump đề_xuất .']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longest_matching_sentences = []\n",
    "for sentence in sentences:\n",
    "    longest_matching_sentences.append(tokenize_sentences(sentence))\n",
    "longest_matching_sentences[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng từ ghép khi tách từ bằng thuật toán Longest Matching: 340\n"
     ]
    }
   ],
   "source": [
    "longest_matching_compounds = []\n",
    "for sentence in longest_matching_sentences:\n",
    "    for word in sentence.split():\n",
    "        if '_' in word: longest_matching_compounds.append(word.lower())\n",
    "\n",
    "print('Số lượng từ ghép khi tách từ bằng thuật toán Longest Matching:', len(longest_matching_compounds))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tách từ thủ công bằng tay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pha lập_công trên đã giúp Rashford giải_hạn bàn_thắng tại sân Old_Trafford kéo_dài 845 phút .',\n",
       " 'Với 3 điểm có được trong trận_đấu này , Quỷ_đỏ đã leo_lên vị_trí thứ 2 trên bảng xếp_hạng Premier_League với 30 điểm , chỉ kém đội đầu_bảng Liverpool 2 điểm .',\n",
       " 'Tổng_thống đắc_cử Joe_Biden được cho đang cân_nhắc việc_cắt_bỏ chương_trình hiện_đại_hoá hạt_nhân trị_giá 1.000 tỷ USD do chính_quyền Tổng_thống đương_nhiệm Donald_Trump đề_xuất .']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('tokenize/manual_tokens.txt', 'r', encoding='utf-8') as f:\n",
    "    manual_tokenize_sentences = []\n",
    "    sentence = ''\n",
    "    for word in f:\n",
    "        if word == '\\n': \n",
    "            manual_tokenize_sentences.append(sentence.strip())\n",
    "            sentence = ''\n",
    "        else: sentence += word.replace('\\n', ' ')\n",
    "manual_tokenize_sentences[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng từ ghép khi tách từ thủ công: 309\n"
     ]
    }
   ],
   "source": [
    "manual_tokenize_compounds = []\n",
    "for sentence in manual_tokenize_sentences:\n",
    "    for word in sentence.split():\n",
    "        if '_' in word: manual_tokenize_compounds.append(word.lower())\n",
    "print('Số lượng từ ghép khi tách từ thủ công:', len(manual_tokenize_compounds))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So sánh kết quả"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng từ ghép không có khi làm thủ công: 73\n",
      "Cụ thể: ['thấy_rõ', 'tháng_12', 'gây_nên', 'đầu_người', 'bắn_lên', 'xảy_ra', 'dẫn_đến', 'nguồn_tin', 'trong_khi', 'giải_đấu', 'đưa_ra', 'xem_là', 'nhà_toán_học', 'gặp_trục_trặc', 'bên_phải', 'dành_thời_gian', 'cho_biết', 'lớn_lên', 'bảng_xếp_hạng', 'bị_hỏng', 'bóng_đá', 'món_ăn', 'người_trước', 'năm_nay', 'người_uống', 'trở_về', 'dòng_máu', 'năm_trường', 'biết_trước', 'vũ_khí_hạt_nhân', 'tăng_đột_biến', 'nói_là', 'gây_tắc', 'hiện_đại', 'đại_diện_cho', 'có_thói_quen', 'bị_tắc', 'người_đến', 'cũng_vậy', 'chiến_đấu_với', 'vận_chuyển', 'tưởng_rằng', 'xe_rác', 'ở_chỗ', 'chống_lại', 'mỗi_ngày', 'cho_đang', 'thứ_2', 'bằng_chứng_ngoại_phạm', 'kết_quả_là', 'được_trang_bị', 'cao_hơn', 'thiếu_máu', 'có_tài', 'diễn_ra', 'thời_gian_đầu', 'có_dấu_hiệu', 'không_vững', 'quả_bóng', 'người_lao_động', 'nhà_cao_tầng', 'trụ_được', 'không_có', 'mạnh_mẽ_hơn', 'hàng_không', 'tốt_hơn', 'gần_đây', 'lý_trường', 'bức_tranh', 'não_giữa', 'cao_nhất', 'có_được', 'nữ_công_nhân']\n",
      "Số lượng từ ghép không có: 41\n",
      "Cụ thể: ['đại_diện', 'covid_-_19', 'mẫu_xe_mới', 'đột_biến', 'roger_federer', 'dấu_hiệu', 'vận_chuyển_hàng_không', 'ngoại_phạm', 'bóng_đá_nội', 'con_người', 'tầm_thấp', 'mạnh_mẽ', 'trục_trặc', 'hiện_đại_hoá', 'các_nguồn_tin', 'donald_trump', 'quỷ_đỏ', 'công_nhân', 'old_trafford', 'bằng_chứng', 'premier_league', 'toán_học', 'viêm_gan', 'kho_vũ_khí', 'tự_chọn', 'thói_quen', 'quản_lý', 'cao_tầng', 'trang_bị', '24_giờ', 'tin_tưởng', 'do_thái', 'nhận_biết', 'kết_quả', 'gói_du_lịch', 'động_mạch', 'kiến_thức', 'giải_đấu_này', 'xếp_hạng', 'joe_biden', 'andy_murray']\n"
     ]
    }
   ],
   "source": [
    "# liệt kê các từ ghép sai\n",
    "wrong_compounds = []\n",
    "for word in longest_matching_compounds:\n",
    "    if word not in manual_tokenize_compounds: wrong_compounds.append(word)\n",
    "wrong_compounds = list(set(wrong_compounds))\n",
    "print('Số lượng từ ghép không có khi làm thủ công:', len(wrong_compounds))\n",
    "print('Cụ thể:', wrong_compounds)\n",
    "\n",
    "# liệt kê các từ không có\n",
    "missing_compounds = []\n",
    "for word in manual_tokenize_compounds:\n",
    "    if word not in longest_matching_compounds: missing_compounds.append(word)\n",
    "    # if word.replace('_',' ') not in vocab: print(word.replace('_',' '))\n",
    "missing_compounds = list(set(missing_compounds))\n",
    "print('Số lượng từ ghép không có:', len(missing_compounds))\n",
    "print('Cụ thể:', missing_compounds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OpenCV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
